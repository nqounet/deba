# 履歴管理型疑似セッション・ワーカー (History-based Pseudo-Session Worker)

## 背景
Gemini などのモデルにおいて、API 呼び出しごとにコンテキストがリセットされるステートレスな性質を補い、長期的なタスク遂行において文脈（コンテキスト）を維持するため。

## コンセプト
真の永続的な通信セッションを維持する代わりに、**「対話履歴（History）を配列として保持し、リクエストのたびに過去の経緯をプロンプトに統合して送信する」** 方式を採用する。これにより、複数のタスクステップにわたって「さっき何をしたか」を LLM が把握した状態で作業を継続できる。

## 動作フロー

1.  **セッション初期化 (`src/ai.ts:ChatSession`)**:
    *   `worker` 起動時に `ChatSession` クラスのインスタンスを作成。
    *   内部に `history: { role, content }[]` 配列を空で用意する。

2.  **メッセージ送信 (`sendMessage`)**:
    *   新しい指示（キューの状態など）を履歴に追加。
    *   これまでの履歴を `USER: ... / MODEL: ...` という形式で一つの長いテキストに結合。
    *   `src/ai.ts:generateContent` を呼び出し、単発の API リクエストとして送信。

3.  **自律的な行動選択**:
    *   LLM は結合された履歴に基づき、現在の状態を判断。
    *   `src/templates/worker_eternal.md` の指示に従い、JSON 形式でアクション（`EXECUTE_TASK`, `WAIT` など）を返却。

4.  **結果のフィードバック**:
    *   タスク実行結果（コード変更やテストの合否）を再び `sendMessage` で LLM に報告。
    *   LLM はその結果を履歴として記憶し、次の行動判断に活かす。

5.  **待機ループ**:
    *   タスクがない場合、LLM は `WAIT` アクションを指示。
    *   TypeScript 側で `fs.watch` を開始し、ファイルが追加されるまで **LLM リクエストを停止**。
    *   ファイル追加イベントを検知したら、ステップ 2 へ戻る。

## 利点
- **実装の堅牢性**: パイプやプロセス維持によるデッドロックのリスクがなく、標準的な CLI 呼び出しの組み合わせで動作する。
- **文脈の維持**: 実行・テスト・修正のサイクルを一つの「会話」として扱えるため、Self-repair の精度が高い。
- **リソース効率**: 待機中は LLM プロセスが動かないため、メモリや CPU 負荷が低い。

## 今後の課題
- **コンテキストの肥大化**: 履歴が長くなりすぎるとトークンコストが増大し、モデルの最大入力サイズを超える。適宜、古い履歴の要約や削除（スライディングウィンドウ）が必要。
- **キャッシュの活用**: Gemini の Context Caching を利用して、共通のプロジェクト構造や過去の履歴をキャッシュし、コストを最適化する。
